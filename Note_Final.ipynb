{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 資料處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Bitscore 標準建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a-1. Actinobacteria Negative Control 之 Bitscore 標準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM actino negative control bit-score threshold\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# create a function can get the datafarme of each control's best bit-score, e-vale and coverage dataframes\n",
    "# hmm domtblout name should be ...aed_I_... NOT ..._I_aed_....\n",
    "def negative_control_df(control_dir, control_names, BitScore_df):\n",
    "    # Create an empty dictionary to store the best bit-scores; best e-vale; best coverage for each hmmsearch\n",
    "    best_bit_scores = {}\n",
    "\n",
    "    # Loop over the hmmsearches and parse the corresponding \"domtblout\" file\n",
    "    for control_name in control_names:\n",
    "        # Load the \"domtblout\" file into a pandas DataFrame\n",
    "        file_path = os.path.join(control_dir, control_name + \".domtblout\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, comment=\"#\", sep='\\s+', header=None)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "        if df.empty:\n",
    "            pattern = r'A_.*_aed'\n",
    "            query_name = re.sub(pattern, 'A_aed', control_name)        \n",
    "            best_bit_scores[query_name] = 0\n",
    "        else:        \n",
    "            # Assign column names to the DataFrame\n",
    "            df.columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "                          \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\",\n",
    "                          \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "            # Calculate the coverage for each hit\n",
    "            df[\"coverage\"] = (df[\"ali_to\"] - df[\"ali_from\"] + 1) / df[\"tlen\"]\n",
    "\n",
    "            # Filter the DataFrame by E-value and coverage, and sort by bit-score\n",
    "            significant_hits = df[(df[\"E-value\"] < 0.001) & (df[\"coverage\"] > 0.50)].sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "            # replace strains name to aed..\n",
    "            pattern = r'A_.*_aed'\n",
    "            query_name = re.sub(pattern, 'A_aed', control_name)\n",
    "\n",
    "            # Extract the best bit-score and store it in the dictionary\n",
    "            if not significant_hits.empty:\n",
    "                best_bit_score = significant_hits.iloc[0][\"score\"]\n",
    "                best_bit_scores[query_name] = best_bit_score\n",
    "            else:\n",
    "                best_bit_scores[query_name] = 0\n",
    "\n",
    "    # create the index names for three df\n",
    "    # Get the strain name\n",
    "    pattern = r'A_.*_aed'\n",
    "    StrainName = re.findall(pattern, control_names[0])\n",
    "    \n",
    "    # create index of bit score\n",
    "    bitscore_name = StrainName[0] + '_bit_score'\n",
    "    BitScore_Name = [bitscore_name]\n",
    "\n",
    "    # create a dataframe of bit score\n",
    "    BitScore_df = pd.DataFrame(best_bit_scores, index=BitScore_Name)\n",
    "\n",
    "    return BitScore_df\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# A_Rhodococcus_jostii_RHA1\n",
    "# Define the directory that contains the \"domtblout\" files\n",
    "control_dir = \"../data/raw/Actino_HMM_Control/Negative/A_Rhodococcus_jostii_RHA1/domtblout/\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension)\n",
    "# Do not use 'A_aedC_RS26365', 'A_aedQ_RS26445', 'A_aedR_RS26450' cause their Non-All homologous\n",
    "control_names = ['A_Rhodococcus_jostii_RHA1_aedA_I_RS26385', 'A_Rhodococcus_jostii_RHA1_aedB_I_RS26395', 'A_Rhodococcus_jostii_RHA1_aedD_RS26370', 'A_Rhodococcus_jostii_RHA1_aedE_RS26375', 'A_Rhodococcus_jostii_RHA1_aedF_I_RS26380', 'A_Rhodococcus_jostii_RHA1_aedG_I_RS26390', 'A_Rhodococcus_jostii_RHA1_aedH_I_RS26400', 'A_Rhodococcus_jostii_RHA1_aedI_RS26405', 'A_Rhodococcus_jostii_RHA1_aedJ_I_RS26410', 'A_Rhodococcus_jostii_RHA1_aedK_I_RS26415', 'A_Rhodococcus_jostii_RHA1_aedL_RS26420', 'A_Rhodococcus_jostii_RHA1_aedM_RS26425', 'A_Rhodococcus_jostii_RHA1_aedN_RS26430', 'A_Rhodococcus_jostii_RHA1_aedO_RS26435', 'A_Rhodococcus_jostii_RHA1_aedP_RS26440']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df, Evalue_df, Coverage_df)\n",
    "RHA1_BitScore = pd.DataFrame()\n",
    "RHA1_BitScore = negative_control_df(control_dir, control_names, RHA1_BitScore)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# A_Mycobacterium_tuberculosis_H37Rv\n",
    "# Define the directory that contains the \"domtblout\" files\n",
    "control_dir = \"../data/raw/Actino_HMM_Control/Negative/A_Mycobacterium_tuberculosis_H37Rv/domtblout\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension)\n",
    "# Do not use 'A_aedC_RS26365', 'A_aedQ_RS26445', 'A_aedR_RS26450' cause their Non-All homologous\n",
    "control_names = ['A_Mycobacterium_tuberculosis_H37Rv_aedA_I_RS26385', 'A_Mycobacterium_tuberculosis_H37Rv_aedB_I_RS26395', 'A_Mycobacterium_tuberculosis_H37Rv_aedD_RS26370', 'A_Mycobacterium_tuberculosis_H37Rv_aedE_RS26375', 'A_Mycobacterium_tuberculosis_H37Rv_aedF_I_RS26380', 'A_Mycobacterium_tuberculosis_H37Rv_aedG_I_RS26390', 'A_Mycobacterium_tuberculosis_H37Rv_aedH_I_RS26400', 'A_Mycobacterium_tuberculosis_H37Rv_aedI_RS26405', 'A_Mycobacterium_tuberculosis_H37Rv_aedJ_I_RS26410', 'A_Mycobacterium_tuberculosis_H37Rv_aedK_I_RS26415', 'A_Mycobacterium_tuberculosis_H37Rv_aedL_RS26420', 'A_Mycobacterium_tuberculosis_H37Rv_aedM_RS26425', 'A_Mycobacterium_tuberculosis_H37Rv_aedN_RS26430', 'A_Mycobacterium_tuberculosis_H37Rv_aedO_RS26435', 'A_Mycobacterium_tuberculosis_H37Rv_aedP_RS26440']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df, Evalue_df, Coverage_df)\n",
    "H37Rv_BitScore = pd.DataFrame()\n",
    "H37Rv_BitScore = negative_control_df(control_dir, control_names, H37Rv_BitScore)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# merge two negative best bit score df\n",
    "Actino_Negative_df = pd.concat([RHA1_BitScore, H37Rv_BitScore], axis=0)\n",
    "\n",
    "# Got the highest bit score of the df\n",
    "Actino_BitScore_Criteria = Actino_Negative_df.max()\n",
    "Actino_BitScore_Criteria = Actino_BitScore_Criteria.iloc[0:]\n",
    "Actino_BitScore_Criteria = Actino_BitScore_Criteria.to_frame()\n",
    "Actino_BitScore_Criteria.columns = ['Criteria_Bitscore']\n",
    "\n",
    "# transpose the DataFrame\n",
    "Actino_BitScore_Criteria_T = Actino_BitScore_Criteria.T\n",
    "\n",
    "# merge all nad Min table\n",
    "Actino_Negative_df = pd.concat([Actino_Negative_df, Actino_BitScore_Criteria_T], axis=0)\n",
    "Actino_Negative_df.to_csv('../data/processed/Final/ForReader/ControlData/Actino_aed/Actino_NegativeBitscore.csv')\n",
    "\n",
    "# done\n",
    "display(Actino_BitScore_Criteria)\n",
    "display(Actino_Negative_df)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a-2 Proteobcateria Negative Control 之 Bitscore 建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM actino negative control bit-score threshold\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# create a function can get the datafarme of each control's best bit-score, e-vale and coverage dataframes\n",
    "# hmm domtblout name should be ...edc_I_... NOT ..._I_edc_....\n",
    "def negative_control_df(control_dir, control_names, BitScore_df):\n",
    "    # Create an empty dictionary to store the best bit-scores; best e-vale; best coverage for each hmmsearch\n",
    "    best_bit_scores = {}\n",
    "\n",
    "    # Loop over the hmmsearches and parse the corresponding \"domtblout\" file\n",
    "    for control_name in control_names:\n",
    "        # Load the \"domtblout\" file into a pandas DataFrame\n",
    "        file_path = os.path.join(control_dir, control_name + \".domtblout\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, comment=\"#\", sep='\\s+', header=None)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "        if df.empty:\n",
    "            pattern = r'P_.*_edc'\n",
    "            query_name = re.sub(pattern, 'P_edc', control_name)         \n",
    "            best_bit_scores[query_name] = 0\n",
    "        else:        \n",
    "            # Assign column names to the DataFrame\n",
    "            df.columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "                          \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\",\n",
    "                          \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "            # Calculate the coverage for each hit\n",
    "            df[\"coverage\"] = (df[\"ali_to\"] - df[\"ali_from\"] + 1) / df[\"tlen\"]\n",
    "\n",
    "            # Filter the DataFrame by E-value and coverage, and sort by bit-score\n",
    "            significant_hits = df[(df[\"E-value\"] < 0.001) & (df[\"coverage\"] > 0.50)].sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "            # replace strains name to aed..\n",
    "            pattern = r'P_.*_edc'\n",
    "            query_name = re.sub(pattern, 'P_edc', control_name)  \n",
    "\n",
    "            # Extract the best bit-score and store it in the dictionary\n",
    "            if not significant_hits.empty:\n",
    "                best_bit_score = significant_hits.iloc[0][\"score\"]\n",
    "                best_bit_scores[query_name] = best_bit_score\n",
    "            else:\n",
    "                best_bit_scores[query_name] = 0\n",
    "\n",
    "    # create the index names for three df\n",
    "    # Get the strain name\n",
    "    pattern = r'P_.*_edc'\n",
    "    StrainName = re.findall(pattern, control_names[0])\n",
    "\n",
    "    # create index of bit score\n",
    "    bitscore_name = StrainName[0] + '_bit_score'\n",
    "    BitScore_Name = [bitscore_name]\n",
    "\n",
    "    # create a dataframe of bit score\n",
    "    BitScore_df = pd.DataFrame(best_bit_scores, index=BitScore_Name)\n",
    "\n",
    "    return BitScore_df\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# P_Comamonas_thiooxidans_CNB1\n",
    "# Define the directory that contains the \"domtblout\" files, 這個genome protein fasta要把discription的文字刪除，因有空格會影響read\n",
    "control_dir = \"../data/raw/Proteo_HMM_NegativeControl/P_Comamonas_thiooxidans_CNB1/\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension); delet 13540\n",
    "control_names = ['P_Comamonas_thiooxidans_CNB1_edc13525_I_', 'P_Comamonas_thiooxidans_CNB1_edc13530', 'P_Comamonas_thiooxidans_CNB1_edc13535', 'P_Comamonas_thiooxidans_CNB1_edc13545', 'P_Comamonas_thiooxidans_CNB1_edc13550', 'P_Comamonas_thiooxidans_CNB1_edc13555', 'P_Comamonas_thiooxidans_CNB1_edc13560', 'P_Comamonas_thiooxidans_CNB1_edc13565', 'P_Comamonas_thiooxidans_CNB1_edc13570_I_', 'P_Comamonas_thiooxidans_CNB1_edc13575', 'P_Comamonas_thiooxidans_CNB1_edc13580_I_', 'P_Comamonas_thiooxidans_CNB1_edc13585', 'P_Comamonas_thiooxidans_CNB1_edc13590', 'P_Comamonas_thiooxidans_CNB1_edc13595']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df)\n",
    "CNB1_BitScore = pd.DataFrame()\n",
    "CNB1_BitScore = negative_control_df(control_dir, control_names, CNB1_BitScore)\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# P_Novosphingobium_sp_strain_Chol11\n",
    "# Define the directory that contains the \"domtblout\" files, 這個genome protein fasta要把discription的文字刪除，因有空格會影響read\n",
    "control_dir = \"../data/raw/Proteo_HMM_NegativeControl/P_Novosphingobium_sp_strain_Chol11/\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension); delet 13540\n",
    "control_names = ['P_Novosphingobium_sp_strain_Chol11_edc13525_I_', 'P_Novosphingobium_sp_strain_Chol11_edc13530', 'P_Novosphingobium_sp_strain_Chol11_edc13535', 'P_Novosphingobium_sp_strain_Chol11_edc13545', 'P_Novosphingobium_sp_strain_Chol11_edc13550', 'P_Novosphingobium_sp_strain_Chol11_edc13555', 'P_Novosphingobium_sp_strain_Chol11_edc13560', 'P_Novosphingobium_sp_strain_Chol11_edc13565', 'P_Novosphingobium_sp_strain_Chol11_edc13570_I_', 'P_Novosphingobium_sp_strain_Chol11_edc13575', 'P_Novosphingobium_sp_strain_Chol11_edc13580_I_', 'P_Novosphingobium_sp_strain_Chol11_edc13585', 'P_Novosphingobium_sp_strain_Chol11_edc13590', 'P_Novosphingobium_sp_strain_Chol11_edc13595']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df)\n",
    "Chol11_BitScore = pd.DataFrame()\n",
    "Chol11_BitScore = negative_control_df(control_dir, control_names, Chol11_BitScore)\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# P_Pseudomonas_putida_DOC21_cluster\n",
    "# Define the directory that contains the \"domtblout\" files, 這個genome protein fasta要把discription的文字刪除，因有空格會影響read\n",
    "control_dir = \"../data/raw/Proteo_HMM_NegativeControl/P_Pseudomonas_putida_DOC21_cluster/\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension); delet 13540\n",
    "control_names = ['P_Pseudomonas_putida_DOC21_cluster1_edc13525_I_', 'P_Pseudomonas_putida_DOC21_cluster1_edc13530', 'P_Pseudomonas_putida_DOC21_cluster1_edc13535', 'P_Pseudomonas_putida_DOC21_cluster1_edc13545', 'P_Pseudomonas_putida_DOC21_cluster1_edc13550', 'P_Pseudomonas_putida_DOC21_cluster1_edc13555', 'P_Pseudomonas_putida_DOC21_cluster1_edc13560', 'P_Pseudomonas_putida_DOC21_cluster1_edc13565', 'P_Pseudomonas_putida_DOC21_cluster1_edc13570_I_', 'P_Pseudomonas_putida_DOC21_cluster1_edc13575', 'P_Pseudomonas_putida_DOC21_cluster1_edc13580_I_', 'P_Pseudomonas_putida_DOC21_cluster1_edc13585', 'P_Pseudomonas_putida_DOC21_cluster1_edc13590', 'P_Pseudomonas_putida_DOC21_cluster1_edc13595']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df)\n",
    "DOC21_BitScore = pd.DataFrame()\n",
    "DOC21_BitScore = negative_control_df(control_dir, control_names, DOC21_BitScore)\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# P_Pseudomonas_stutzeri_Chol-1\n",
    "# Define the directory that contains the \"domtblout\" files, 這個genome protein fasta要把discription的文字刪除，因有空格會影響read\n",
    "control_dir = \"../data/raw/Proteo_HMM_NegativeControl/P_Pseudomonas_stutzeri_Chol-1/\"\n",
    "\n",
    "# Define the names of the control_names (without the file extension); delet 13540\n",
    "control_names = ['P_Pseudomonas_stutzeri_Chol-1_edc13525_I_', 'P_Pseudomonas_stutzeri_Chol-1_edc13530', 'P_Pseudomonas_stutzeri_Chol-1_edc13535', 'P_Pseudomonas_stutzeri_Chol-1_edc13545', 'P_Pseudomonas_stutzeri_Chol-1_edc13550', 'P_Pseudomonas_stutzeri_Chol-1_edc13555', 'P_Pseudomonas_stutzeri_Chol-1_edc13560', 'P_Pseudomonas_stutzeri_Chol-1_edc13565', 'P_Pseudomonas_stutzeri_Chol-1_edc13570_I_', 'P_Pseudomonas_stutzeri_Chol-1_edc13575', 'P_Pseudomonas_stutzeri_Chol-1_edc13580_I_', 'P_Pseudomonas_stutzeri_Chol-1_edc13585', 'P_Pseudomonas_stutzeri_Chol-1_edc13590', 'P_Pseudomonas_stutzeri_Chol-1_edc13595']\n",
    "\n",
    "# Use positive_control_df function to get the df (control_dir, control_names, BitScore_df)\n",
    "Chol01_BitScore = pd.DataFrame()\n",
    "Chol01_BitScore = negative_control_df(control_dir, control_names, Chol01_BitScore)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# merge four negative best bit score df\n",
    "Proteo_Negative_df = pd.concat([CNB1_BitScore, Chol11_BitScore, DOC21_BitScore, Chol01_BitScore], axis=0)\n",
    "\n",
    "# Got the highest bit score of the df\n",
    "Proteo_BitScore_Criteria = Proteo_Negative_df.max()\n",
    "Proteo_BitScore_Criteria = Proteo_BitScore_Criteria.iloc[0:]\n",
    "Proteo_BitScore_Criteria = Proteo_BitScore_Criteria.to_frame()\n",
    "Proteo_BitScore_Criteria.columns = ['Criteria_Bitscore']\n",
    "\n",
    "# transpose the DataFrame\n",
    "Proteo_BitScore_Criteria_T = Proteo_BitScore_Criteria.T\n",
    "\n",
    "# merge all nad Min table\n",
    "Proteo_Negative_df = pd.concat([Proteo_Negative_df, Proteo_BitScore_Criteria_T], axis=0)\n",
    "Proteo_Negative_df.to_csv('../data/processed/Final/ForReader/ControlData/Proteo_edc/Proteo_NegativeBitscore.csv')\n",
    "\n",
    "# done\n",
    "display(Proteo_BitScore_Criteria)\n",
    "display(Proteo_Negative_df)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. 利用上述生成的標準來篩選合格的 MAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b-1. Actinobacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-1a 在 HMMER 分析中用 Bitscore 標準來篩選出相似的 Protein of MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actino_HMM_MAGs\n",
    "#需先進行前步驟的cell (1. 使用 negative control 來獲得合適的bit score)\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#-------------------------------\n",
    "#Aed Cluster to MAGs\n",
    "\n",
    "#Define the directory that contains the \"domtblout\" files.需要刪除discription\n",
    "domtblout_dir = \"../data/raw/Actino_HMM_MAGs_domtblout/\"\n",
    "\n",
    "#Create an empty dictionary to store the target name for each hmmsearch\n",
    "MAGs_Hits = {} #create a dictionary\n",
    "MAGs_Hits_name = [] #創建 List，存入篩選到的 MAGs ID\n",
    "\n",
    "#covert criteria dataframe to serires\n",
    "Actino_BitScore_Criteria_S = Actino_BitScore_Criteria['Criteria_Bitscore']\n",
    "Actino_BitScore_Criteria_S = Actino_BitScore_Criteria_S.astype(float)    \n",
    "\n",
    "#create a dataframe for a all hits \n",
    "columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "           \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\",\n",
    "           \"hmm_to\", \"ali_from\", \"ali_to\", \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "\n",
    "All_aed_Hits_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "#Loop over the HMM DOMTBLOUT files and filter the results based on bit score, e-value and coverage\n",
    "#hmm name and bit score are in the Actino_BitScore_Criteria series\n",
    "for hmmsearch, threshold in Actino_BitScore_Criteria_S.items():\n",
    "    #Load the \"domtblout\" file into a pandas DataFrame\n",
    "    file_path = os.path.join(domtblout_dir, hmmsearch + \".domtblout\")\n",
    "    df = pd.read_csv(file_path, comment=\"#\", sep='\\s+', header=None)    \n",
    "    #Assign column names to the DataFrame\n",
    "    df.columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "                  \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\",\n",
    "                  \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "\n",
    "    #Calculate the coverage for each hit\n",
    "    df[\"coverage\"] = (df[\"ali_to\"] - df[\"ali_from\"] + 1) / df[\"tlen\"]\n",
    "    \n",
    "    #Filter the DataFrame by E-value, coverage, and bit-score\n",
    "    significant_hits = df[(df[\"E-value\"] < 0.001) & (df[\"coverage\"] > 0.50) & (df[\"score\"] > threshold)]\n",
    "\n",
    "    #Extract Target nmae and store it in the dictionary\n",
    "    if not significant_hits.empty:\n",
    "        MAGs_Hits_name = significant_hits[\"target_name\"].tolist()\n",
    "        MAGs_Hits[hmmsearch] = MAGs_Hits_name\n",
    "    else:\n",
    "        MAGs_Hits_name = None\n",
    "        MAGs_Hits[hmmsearch] = MAGs_Hits_name\n",
    "    \n",
    "    #add hits table to a df\n",
    "    All_aed_Hits_df = pd.concat([significant_hits, All_aed_Hits_df], axis=0)\n",
    "\n",
    "#done\n",
    "print('done')\n",
    "print('unique query name/numbers: ', All_aed_Hits_df['query_name'].unique(), ' / ', len(All_aed_Hits_df['query_name'].unique()))\n",
    "All_aed_Hits_df.to_csv('../data/processed/All_aed_Hits_df_bitscore.csv')    \n",
    "All_aed_Hits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-1b 整理出各個 MAGs 所具有的 Protein Hits，再用hits數量進行篩選(>=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got target name and query name\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#read table\n",
    "All_aed_Hits_df = pd.read_csv('../data/processed/All_aed_Hits_df_bitscore.csv') \n",
    "\n",
    "#Got target name and query name    \n",
    "All_aed_Hits_TargetAndQuery = All_aed_Hits_df[['target_name', 'query_name']]\n",
    "\n",
    "#Load a Dataframe with the lookup values for merge protein id to MAGs and merge them\n",
    "TarToMAGs_aed = pd.read_csv('../data/interim/Actino_aed/aed_All_TarToMAGsID.csv')\n",
    "\n",
    "#use merge() function to join the MAGsID data\n",
    "aed_hits_TargetAndMAGsID = pd.merge(All_aed_Hits_TargetAndQuery, TarToMAGs_aed, on='target_name', how='left')                                                                               \n",
    "\n",
    "#check the null value\n",
    "print('Any Null in TargetToMAGsID: ', aed_hits_TargetAndMAGsID['MAGsID'].isnull().any())\n",
    "\n",
    "#create the crosstab table (like heatmap)\n",
    "aed_hits_heatmap = pd.crosstab(aed_hits_TargetAndMAGsID['query_name'], aed_hits_TargetAndMAGsID['MAGsID'], dropna=False)\n",
    "aed_hits_heatmap = aed_hits_heatmap.transpose()\n",
    "#aed_hits_heatmap\n",
    "#aed_hits_heatmap.to_csv('../data/processed/aed_hits_heatmap_bitscore.csv')\n",
    "\n",
    "#Count the non-zero values in hmm profiles hit row to calculate the number of different HMM profiles that have hits in a given MAG. \n",
    "def count_nonzero(row):\n",
    "    return len(row[row != 0])\n",
    "\n",
    "num_hits = aed_hits_heatmap.apply(count_nonzero, axis=1)\n",
    "aed_hits_heatmap['num_hits'] = num_hits\n",
    "\n",
    "#sort them by hits numer\n",
    "aed_hits_heatmap = aed_hits_heatmap.sort_values(by=\"num_hits\", ascending=False)\n",
    "\n",
    "#extract > 8 hmm profiles hits and the necessary hits (aedA、aedB、aedJ)\n",
    "aed_hits_FinalFilter =  aed_hits_heatmap[(aed_hits_heatmap['num_hits'] >= 8)]\n",
    "#>7 = 326, >8 = 167, >9 = 70, >10 = 17 用8較為恰當 大於一半的query gene\n",
    "\n",
    "#Reset index and move index column to first position\n",
    "aed_hits_FinalFilter.index.name = None\n",
    "aed_hits_FinalFilter = aed_hits_FinalFilter.reset_index()\n",
    "aed_hits_FinalFilter.insert(0, 'index', aed_hits_FinalFilter.pop('index'))\n",
    "\n",
    "#rename MAGsID\n",
    "aed_hits_FinalFilter = aed_hits_FinalFilter.rename(columns={'index': 'genome_id'})\n",
    "\n",
    "#extract the MAGsID and num_hits column\n",
    "aed_Positive_MAGsID = aed_hits_FinalFilter[['genome_id', 'num_hits']]\n",
    "\n",
    "#done\n",
    "print('done')\n",
    "aed_Positive_MAGsID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-1c 將篩選出的 MAGS 與相關的資料彙整至 reference 的 MAGs metadata 中，再整理出一個適合進行後續 R 繪圖分析的表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需先執行上一個cell\n",
    "#open metagenome csv files\n",
    "metagenmoes_df = pd.read_csv('../data/external/genome_metadata_editForAnalysis_NotReference.csv')\n",
    "\n",
    "#merge positive MAGs with metagenome\n",
    "aed_Positive_metagenomes_df = pd.merge(aed_Positive_MAGsID, metagenmoes_df, on='genome_id', how='left')\n",
    "\n",
    "#extract certain column\n",
    "aed_Positive_metagenomes_df = aed_Positive_metagenomes_df[['genome_id', 'metagenome_id', 'taxonomy', 'ecosystem', 'ecosystem_category', 'num_hits', 'longitude', 'latitude']]\n",
    "\n",
    "#extract phylum and class from taxonomy column and expand to new column\n",
    "aed_Positive_metagenomes_df['Phylum'] = aed_Positive_metagenomes_df['taxonomy'].str.extract('(p__\\w+)', expand=True)\n",
    "aed_Positive_metagenomes_df['Class'] = aed_Positive_metagenomes_df['taxonomy'].str.extract('(c__\\w+)', expand=True)\n",
    "\n",
    "#print non-duplicated values in ecosystem_type than check the lable\n",
    "#print(aed_Positive_metagenomes_df['ecosystem_type'].unique())\n",
    "#aed_Positive_metagenomes_df\n",
    "\n",
    "#check the None value in ecosystem column Create a Boolean mask to identify NaN values\n",
    "#mask = aed_addEco_df.isna()\n",
    "#aed_addEco_df_nan_rows = aed_addEco_df[mask.any(axis=1)]\n",
    "#aed_addEco_df_nan_rows\n",
    "\n",
    "#remove, add and rearrange column\n",
    "aed_Positive_metagenomes_df.drop('taxonomy', axis=1, inplace=True)\n",
    "aed_Positive_metagenomes_df = aed_Positive_metagenomes_df.reindex(columns=['genome_id', 'metagenome_id', 'num_hits', 'Phylum', 'Class', 'ecosystem', 'ecosystem_category', 'longitude', 'latitude'])\n",
    "aed_Positive_metagenomes_df['Homologous_cluster']='Actino_aed_cluster'\n",
    "\n",
    "#check phylum data\n",
    "print(aed_Positive_metagenomes_df['Phylum'].unique())\n",
    "print('Any Null in aed_Positive_metagenomes_df:\\n', aed_Positive_metagenomes_df.isnull().any())\n",
    "\n",
    "#write file\n",
    "aed_Positive_metagenomes_df.to_csv('../data/processed/Final/Actino/aed_PositiveHits_ForR_loose.csv')\n",
    "print('Number of p__UBP10: ', aed_Positive_metagenomes_df[aed_Positive_metagenomes_df['Phylum'] == 'p__UBP10'].shape[0])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b-2 Proteobacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-2a 在 HMMER 分析中用 Bitscore 標準來篩選出相似的 Protein of MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proteo_HMM_MAGs\n",
    "# 需執行前一個cell程式\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Aed Cluster to MAGs\n",
    "# Define the directory that contains the \"domtblout\" files.需要刪除discription\n",
    "domtblout_dir = \"../data/raw/Proteo_HMM_MAGs_domtblout/\"\n",
    "\n",
    "# Create an empty dictionary to store the target name for each hmmsearch\n",
    "MAGs_Hits = {}\n",
    "MAGs_Hits_name = []\n",
    "\n",
    "# covert criteria dataframe to serires\n",
    "Proteo_BitScore_Criteria_S = Proteo_BitScore_Criteria['Criteria_Bitscore']\n",
    "Proteo_BitScore_Criteria_S = Proteo_BitScore_Criteria_S.astype(float)  \n",
    "\n",
    "# create a dataframe for a all hits \n",
    "columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "           \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\",\n",
    "           \"hmm_to\", \"ali_from\", \"ali_to\", \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "\n",
    "All_edc_Hits_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Loop over the HMM DOMTBLOUT files and filter the results based on bit score, e-value and coverage\n",
    "# hmm name and bit score are in the Actino_BitScore_Criteria series\n",
    "for hmmsearch, threshold in Proteo_BitScore_Criteria_S.items():\n",
    "    # Load the \"domtblout\" file into a pandas DataFrame\n",
    "    file_path = os.path.join(domtblout_dir, hmmsearch + \".domtblout\")\n",
    "    df = pd.read_csv(file_path, comment=\"#\", sep='\\s+', header=None)    \n",
    "    # Assign column names to the DataFrame\n",
    "    df.columns = [\"target_name\", \"accession\", \"tlen\", \"query_name\", \"accession2\", \"qlen\", \"E-value\", \"score\", \"bias\",\n",
    "                  \"num_domains_index\", \"num_domains_total\", \"c-Evalue\", \"i-Evalue\", \"score2\", \"bias2\", \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\",\n",
    "                  \"env_from\", \"env_to\", \"acc\", \"description\"]\n",
    "\n",
    "    # Calculate the coverage for each hit\n",
    "    df[\"coverage\"] = (df[\"ali_to\"] - df[\"ali_from\"] + 1) / df[\"tlen\"]\n",
    "    \n",
    "    # Filter the DataFrame by E-value, coverage, and bit-score\n",
    "    significant_hits = df[(df[\"E-value\"] < 0.001) & (df[\"coverage\"] > 0.50) & (df[\"score\"] > threshold)]\n",
    "\n",
    "    # Extract Target nmae and store it in the dictionary\n",
    "    if not significant_hits.empty:\n",
    "        MAGs_Hits_name = significant_hits[\"target_name\"].tolist()\n",
    "        MAGs_Hits[hmmsearch] = MAGs_Hits_name\n",
    "    else:\n",
    "        MAGs_Hits_name = None\n",
    "        MAGs_Hits[hmmsearch] = MAGs_Hits_name\n",
    "    \n",
    "    # add hits table to a df\n",
    "    All_edc_Hits_df = pd.concat([significant_hits, All_edc_Hits_df], axis=0)\n",
    "\n",
    "# done\n",
    "print('done')\n",
    "print('unique query name: ', All_edc_Hits_df['query_name'].unique(), ' / ', len(All_edc_Hits_df['query_name'].unique()))\n",
    "All_edc_Hits_df.to_csv('../data/processed/All_edc_Hits_df_bitscore.csv')  \n",
    "All_edc_Hits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-2b 整理出各個 MAGs 所具有的 Protein Hits，再用hits數量進行篩選(>=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got target name and query name\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "All_edc_Hits_df = pd.read_csv('../data/processed/All_edc_Hits_df_bitscore.csv') \n",
    "All_edc_Hits_TargetAndQuery = All_edc_Hits_df[['target_name', 'query_name']]\n",
    "\n",
    "# Load a Dataframe with the lookup values for merge protein id to MAGs and merge them\n",
    "TarToMAGs_edc = pd.read_csv('../data/interim/edc_All_TarToMAGsID.csv')\n",
    "\n",
    "# use merge() function to join the MAGsID data\n",
    "edc_hits_TargetAndMAGsID = pd.merge(All_edc_Hits_TargetAndQuery, TarToMAGs_edc, on='target_name', how='left')                                                                               \n",
    "\n",
    "# check the null value\n",
    "print('Any Null in TargetToMAGsID: ', edc_hits_TargetAndMAGsID['MAGsID'].isnull().any())\n",
    "\n",
    "# create the crosstab table (like heatmap)\n",
    "edc_hits_heatmap = pd.crosstab(edc_hits_TargetAndMAGsID['query_name'], edc_hits_TargetAndMAGsID['MAGsID'], dropna=False)\n",
    "edc_hits_heatmap = edc_hits_heatmap.transpose()\n",
    "edc_hits_heatmap\n",
    "# edc_hits_heatmap.to_csv('../data/processed/edc_hits_heatmap_bitscore.csv')\n",
    "\n",
    "# Count the non-zero values in hmm profiles hit row to calculate the number of different HMM profiles that have hits in a given MAG. \n",
    "def count_nonzero(row):\n",
    "    return len(row[row != 0])\n",
    "\n",
    "num_hits = edc_hits_heatmap.apply(count_nonzero, axis=1)\n",
    "edc_hits_heatmap['num_hits'] = num_hits\n",
    "\n",
    "# sort them by hits numer\n",
    "edc_hits_heatmap = edc_hits_heatmap.sort_values(by=\"num_hits\", ascending=False)\n",
    "\n",
    "# extract >8 hmm profiles hits and the necessary hits (aedA、aedB、aedJ)\n",
    "edc_hits_FinalFilter =  edc_hits_heatmap[(edc_hits_heatmap['num_hits'] >= 8)]\n",
    "# >7 = 1020, >8 = 597, >9 = 294, >10 = 111 先用8看看 大於一半的query gene\n",
    "\n",
    "# Reset index and move index column to first position\n",
    "edc_hits_FinalFilter.index.name = None\n",
    "edc_hits_FinalFilter = edc_hits_FinalFilter.reset_index()\n",
    "edc_hits_FinalFilter.insert(0, 'index', edc_hits_FinalFilter.pop('index'))\n",
    "\n",
    "# rename MAGsID\n",
    "edc_hits_FinalFilter = edc_hits_FinalFilter.rename(columns={'index': 'genome_id'})\n",
    "\n",
    "# extract the MAGsID and num_hits column\n",
    "edc_Positive_MAGsID = edc_hits_FinalFilter[['genome_id', 'num_hits']]\n",
    "edc_Positive_MAGsID\n",
    "\n",
    "# done\n",
    "print('done')\n",
    "edc_Positive_MAGsID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b-2c 將篩選出的 MAGS 與相關的資料彙整至 reference 的 MAGs metadata 中，再整理出一個適合進行後續 R 繪圖分析的表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需先執行上一個cell\n",
    "\n",
    "# open metagenome csv files\n",
    "metagenmoes_df = pd.read_csv('../data/external/genome_metadata_editForAnalysis_NotReference.csv')\n",
    "\n",
    "# merge positive MAGs with metagenome\n",
    "edc_Positive_metagenomes_df = pd.merge(edc_Positive_MAGsID, metagenmoes_df, on='genome_id', how='left')\n",
    "\n",
    "# print(edc_Positive_metagenomes_df['ecosystem_category'].unique())\n",
    "# print(edc_Positive_metagenomes_df['ecosystem_type'].unique())\n",
    "# display(edc_Positive_metagenomes_df[edc_Positive_metagenomes_df['ecosystem_type'] == 'Bacteria']) #Digestive system, Anaerobic\n",
    "\n",
    "# extract certain column\n",
    "edc_Positive_metagenomes_df = edc_Positive_metagenomes_df[['genome_id', 'metagenome_id','taxonomy', 'ecosystem', 'ecosystem_category','num_hits', 'longitude', 'latitude']]\n",
    "\n",
    "# extract phylum and class from taxonomy column and expand to new column\n",
    "edc_Positive_metagenomes_df['Phylum'] = edc_Positive_metagenomes_df['taxonomy'].str.extract('(p__\\w+)', expand=True)\n",
    "edc_Positive_metagenomes_df['Class'] = edc_Positive_metagenomes_df['taxonomy'].str.extract('(c__\\w+)', expand=True)\n",
    "\n",
    "# # print non-duplicated values in ecosystem_type than check the lable\n",
    "# print(edc_Positive_metagenomes_df['ecosystem_type'].unique())\n",
    "\n",
    "# # check the None value in ecosystem column Create a Boolean mask to identify NaN values\n",
    "# mask = edc_addEco_df.isna()\n",
    "# edc_addEco_df_nan_rows = edc_addEco_df[mask.any(axis=1)]\n",
    "# edc_addEco_df_nan_rows\n",
    "\n",
    "# remove, add and rearrange column\n",
    "edc_Positive_metagenomes_df.drop('taxonomy', axis=1, inplace=True)\n",
    "edc_Positive_metagenomes_df = edc_Positive_metagenomes_df.reindex(columns=['genome_id', 'metagenome_id', 'num_hits', 'Phylum', 'Class', 'ecosystem', 'ecosystem_category', 'longitude', 'latitude'])\n",
    "edc_Positive_metagenomes_df['Homologous_cluster']='Proteo_edc_cluster'\n",
    "\n",
    "#check phylum data and null value\n",
    "print(edc_Positive_metagenomes_df['Phylum'].unique())\n",
    "print('Any Null in edc_Positive_metagenomes_df:\\n', edc_Positive_metagenomes_df.isnull().any())\n",
    "\n",
    "# write file\n",
    "edc_Positive_metagenomes_df.to_csv('../data/processed/Final/Proteo/edc_PositiveHits_ForR_loose.csv')\n",
    "print('doen')\n",
    "print('Number of p__UBP10:', edc_Positive_metagenomes_df[edc_Positive_metagenomes_df['Phylum'] == 'p__UBP10'].shape[0])\n",
    "edc_Positive_metagenomes_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
